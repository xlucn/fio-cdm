#!/usr/bin/env python
import os
import sys
import json
import shutil
import argparse
import logging
import configparser
import subprocess


def readable2byte(raw):
    num = raw.lower().rstrip("b").rstrip("i")

    units = {'k': 1, 'm': 2, 'g': 3, 't': 4}
    if num[-1] in units.keys():
        return int(num[:-1]) * 1024 ** units[num[-1]]
    elif num[-1].isdigit():
        return int(num)
    else:
        logging.error("Unrecognised size: %s. Largest unit allowed is TB", raw)
        exit(1)


def byte2readable(num):
    for unit in ['', 'Ki', 'Mi', 'Gi']:
        if abs(num) < 1024.0:
            return "%3.1f%sB" % (num, unit)
        num /= 1024.0
    return "%.1f%sB" % (num, 'Ti')


class Job:
    def __init__(self):
        self._jobs = []
        self._jobfile_name = 'jobfile'
        self._testfile_name = '.fio_testmark'
        self._blocksize = {'seq': '1m', 'rnd': '4k'}
        self._config = configparser.ConfigParser(allow_no_value=True)
        self._config.read_dict({
            'global': {
                'ioengine': 'windowsaio' if os.name == 'nt' else 'libaio',
                'filename': self._testfile_name,
                # Escape colon in disk label on Windows
                'directory': os.path.realpath(args.target).replace(':', '\\:'),
                'size': args.size,
                'direct': '1',
                # borrowed configuration from shell version
                'runtime': '25',
                'ramp_time': '5',
                'refill_buffers': None,
                'norandommap': None,
                'randrepeat': '0',
                'allrandrepeat': '0',
                'group_reporting': None
            }
        })
        if args.zero_buffers:
            self._config.read_dict({'global': {'zero_buffers': None}})
        # Windows does not support pthread mutexes, suppress the warning
        if os.name == 'nt':
            self._config.read_dict({'global': {'thread': None}})

    def _jobname_templ(self, job):
        return "{}-{{rw}}-{}-q{}-t{}".format(job["rnd"],
                                             job["bs"],
                                             job["q"],
                                             job["t"])

    def _displayname(self, job):
        return "{}{} Q{:<2}T{:<2}".format(job["rnd"],
                                          job["bs"],
                                          job["q"],
                                          job["t"]).upper()

    def _create_jobfile(self, jobfile):
        if jobfile == '-':
            self._config.write(sys.stdout, space_around_delimiters=False)
        else:
            with open(jobfile, 'w') as f:
                self._config.write(f, space_around_delimiters=False)

    def create_job(self, rnd_type, queue_size, thread_num):
        try:
            blocksize = self._blocksize[rnd_type]
        except KeyError:
            logging.error("Job type only accepts \"seq\" and \"rnd\"")
            exit(1)

        job = {
            "rnd": rnd_type,
            "bs": blocksize,
            "q": queue_size,
            "t": thread_num
        }
        self._jobs.append(job)

        for rw in ["read", "write", "rw"] if args.mix else ["read", "write"]:
            self._config.read_dict({
                self._jobname_templ(job).format(rw=rw): {
                    'rw': rw if rnd_type == 'seq' else 'rand' + rw,
                    'bs': blocksize,
                    'rwmixread': args.mix,
                    'iodepth': queue_size,
                    'numjobs': thread_num,
                    'loops': args.number,
                    'stonewall': None
                }
            })

    def run(self):
        if args.dump_jobfile:
            self._create_jobfile(args.dump_jobfile)
            exit()
        else:
            self._create_jobfile(self._jobfile_name)

        space_info = self._check_disk_space()
        print("tests: {}, size: {}, target: {} {}".format(
            args.number,
            args.size,
            os.path.realpath(args.target),
            space_info
        ))

        try:
            output = subprocess.check_output(['fio', '--output-format', 'json',
                                              self._jobfile_name])
        except KeyboardInterrupt:
            logging.info('interrupted, cleaning up before exit...')
            exit()
        finally:
            if os.path.exists(self._jobfile_name):
                os.remove(self._jobfile_name)
            if os.path.exists(os.path.join(args.target, self._testfile_name)):
                os.remove(os.path.join(args.target, self._testfile_name))

        fio_output = json.loads(output)
        # rearrange to make jobname as keys
        info = {job.pop("jobname"): job for job in fio_output["jobs"]}
        logging.debug(info)

        self._print_result(info)

    def _print_result(self, info):
        def _print_result_line(job, name, f):
            jobname_templ = self._jobname_templ(job)
            read = info.get(jobname_templ.format(rw="read"))
            write = info.get(jobname_templ.format(rw="write"))
            mix = info.get(jobname_templ.format(rw="rw"))
            print(template_row.format(
                jobname=name,
                read=f(read['read']),
                write=f(write['write']),
                mix=(f(mix['write']) * (100 - args.mix) +
                     f(mix['read']) * args.mix) / 100.0 if args.mix else None
            ))

        if args.mix:
            print("|Name        | Read(MB/s)|Write(MB/s)|  Mix(MB/s)|\n"
                  "|------------|-----------|-----------|-----------|")
            template_row = "|{jobname}|{read:11.2f}|{write:11.2f}|{mix:11.2f}|"
        else:
            print("|Name        | Read(MB/s)|Write(MB/s)|\n"
                  "|------------|-----------|-----------|")
            template_row = "|{jobname}|{read:11.2f}|{write:11.2f}|"

        for job in self._jobs:
            _print_result_line(job, self._displayname(job),
                               lambda d: d['bw_bytes'] / 10**6)
            if job['rnd'] == 'rnd' and args.extra_info:
                _print_result_line(job, "... IOPS    ",
                                   lambda d: d['iops'])
                _print_result_line(job, "... latency ",
                                   lambda d: d['lat_ns']['mean'] / 1000)

    def _check_disk_space(self):
        du = shutil.disk_usage(args.target)
        needed = readable2byte(args.size)
        info = "{}/{}".format(byte2readable(du.used), byte2readable(du.total))

        if du.free > needed:
            return info
        else:
            logging.error("Not enough space available in %s:",
                          args.target)
            logging.error("Needed: %s. Available: %s",
                          byte2readable(needed),
                          byte2readable(du.free))
            exit(1)


def get_parser():
    parser = argparse.ArgumentParser(
        description='A python script to show disk test results with fio')
    parser.add_argument('target', nargs='?', default='.',
                        help='The path of the directory to test. '
                             'Default to current directory.')
    parser.add_argument('-0', dest='zero_buffers', action='store_true',
                        help='Initialize buffers with zeros. '
                             'Default to use random buffers.')
    parser.add_argument('-a', metavar='job', dest='jobs', action="append",
                        help='Manually add multiple jobs. Format is '
                             '"seq|rnd,<queue depth>,<thread number>". '
                             'This overrides the preset jobs. '
                             'This option can be used more than once.')
    parser.add_argument('-E', dest='extra_info', action='store_false',
                        help='Disable extra information (iops, latency) for '
                             'random IO tests. Default is enabled.')
    parser.add_argument('-f', metavar='jobfile', dest='dump_jobfile',
                        help='Save jobfile and quit without running fio. '
                             'Use "-" to print to stdout.')
    parser.add_argument('-n', metavar='number', dest='number',
                        type=int, default=5,
                        help='Number of tests, default is 5.')
    parser.add_argument('-s', metavar='size', dest='size', default='1G',
                        help='The size of file I/O. '
                             'It is directly passed to fio. '
                             'Default is 1G.')
    parser.add_argument('-x', metavar='mix', dest='mix',
                        type=float, nargs="?", const=70, default=0,
                        help='Add mixed rw test. Default is disabled. '
                             '<mix> is read percentage. Default is 70.')
    # hidden option, enable to show debug information
    parser.add_argument('-g', dest='debug', action='store_true',
                        help=argparse.SUPPRESS)
    return parser


if __name__ == '__main__':
    # TODO: Real-time visual feedback, with fio --debug=io? Seams hard.
    # TODO: Linux: vendor and model with lsblk -o +VENDOR,MODEL or /sys/block/*/device/{vendor,model}
    # TODO: Specify device instead of directory
    # Unit of I/O speed, use MB/s(10^6) instead of MiB/s(2^30).
    parser = get_parser()
    args = parser.parse_args()
    logging.basicConfig(level=logging.DEBUG if args.debug else logging.INFO,
                        format="%(message)s")

    logging.debug(args)

    fio_job = Job()
    if args.jobs:
        for job in args.jobs:
            rnd_type, qd, tn = job.split(',')
            fio_job.create_job(rnd_type, int(qd), int(tn))
    else:
        fio_job.create_job('seq',  8,  1)
        fio_job.create_job('seq',  1,  1)
        fio_job.create_job('rnd', 32, 16)
        fio_job.create_job('rnd',  1,  1)
    fio_job.run()
